[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Stroke Prediction – Final Project",
    "section": "",
    "text": "Welcome to my STA6257 final project on stroke prediction using machine learning.\nUse the navigation bar above to explore each section."
  },
  {
    "objectID": "sections/results.html",
    "href": "sections/results.html",
    "title": "Results",
    "section": "",
    "text": "This section presents the performance of all six machine-learning models evaluated on the test dataset. Because the dataset is highly imbalanced (~5% stroke cases), accuracy alone is misleading, so emphasis is placed on sensitivity, specificity, and AUC.\n\n\nEvaluation Function\nAll models were evaluated using the same function:\n```r evaluate_model &lt;- function(model, test_data, positive_class = “Yes”) { pred_class &lt;- predict(model, newdata = test_data) pred_prob &lt;- predict(model, newdata = test_data, type = “prob”)[, positive_class]\ncm &lt;- confusionMatrix(pred_class, test_data$stroke, positive = positive_class)\nroc_obj &lt;- roc( response = test_data$stroke, predictor = pred_prob, levels = c(“No”, “Yes”) )\nlist( cm = cm, auc = auc(roc_obj), roc_obj = roc_obj ) }\n\nModel Results\n\nEach model was evaluated with the function above: res_glm &lt;- evaluate_model(fit_glm, test_data) res_rpart &lt;- evaluate_model(fit_rpart, test_data) res_rf &lt;- evaluate_model(fit_rf, test_data) res_gbm &lt;- evaluate_model(fit_gbm, test_data) res_knn &lt;- evaluate_model(fit_knn, test_data) res_svm &lt;- evaluate_model(fit_svm, test_data)\n\nAUC Values\n\n\n\n\nModel\nAUC\n\n\n\n\nLogistic Regression\n0.8167\n\n\nDecision Tree\n0.6950\n\n\nRandom Forest\n0.8050\n\n\nGradient Boosting (GBM)\n0.8100\n\n\nk-Nearest Neighbors\n0.6784\n\n\nSVM (Radial)\n0.6390\n\n\n\nHighest AUC: Logistic Regression (0.8167), GBM (0.810), and Random Forest (0.805).\n\nConfusion Matrices (Test Set) Most models predicted every case as “No Stroke”, resulting in 0% sensitivity:\n\nLogistic Regression res_glm$cm\nDecision Tree res_rpart$cm\nRandom Forest res_rf$cm\nGBM res_gbm$cm\nkNN res_knn$cm\nSVM res_svm$cm\nAcross models:\n\nTN (True Negatives) were high\nFP (False Positives) were very low\nTP = 0 almost always\nSensitivity = 0 for 5 out of 6 models\n\nThis is a typical outcome in highly imbalanced medical datasets.\n\nROC Curve Comparison plot(res_glm\\(roc_obj, col=\"black\", lwd=2, main=\"ROC Curves for Stroke Prediction (6 Models)\")\nplot(res_rpart\\)roc_obj, col=“orange”, lwd=2, add=TRUE) plot(res_rf\\(roc_obj,    col=\"red\",    lwd=2, add=TRUE)\nplot(res_gbm\\)roc_obj, col=“blue”, lwd=2, add=TRUE) plot(res_knn\\(roc_obj,   col=\"brown\",  lwd=2, add=TRUE)\nplot(res_svm\\)roc_obj, col=“darkgreen”, lwd=2, add=TRUE)\n\nROC Interpretation\n\nGBM (blue) and Random Forest (red) show the best separation.\nLogistic Regression (black) also performs well.\nkNN, SVM, and the Decision Tree show weaker performance.\n\nThis matches the AUC results.\n\nModel Comparison Table model_comparison &lt;- tibble::tibble( Model = c(“Logistic Regression”, “Decision Tree”, “Random Forest”, “Gradient Boosting (GBM)”, “k-Nearest Neighbors”, “SVM (Radial)”),\n\nAccuracy = c(res_glm\\(cm\\)overall[“Accuracy”], res_rpart\\(cm\\)overall[“Accuracy”], res_rf\\(cm\\)overall[“Accuracy”], res_gbm\\(cm\\)overall[“Accuracy”], res_knn\\(cm\\)overall[“Accuracy”], res_svm\\(cm\\)overall[“Accuracy”]),\nSensitivity = c(res_glm\\(cm\\)byClass[“Sensitivity”], res_rpart\\(cm\\)byClass[“Sensitivity”], res_rf\\(cm\\)byClass[“Sensitivity”], res_gbm\\(cm\\)byClass[“Sensitivity”], res_knn\\(cm\\)byClass[“Sensitivity”], res_svm\\(cm\\)byClass[“Sensitivity”]),\nSpecificity = c(res_glm\\(cm\\)byClass[“Specificity”], res_rpart\\(cm\\)byClass[“Specificity”], res_rf\\(cm\\)byClass[“Specificity”], res_gbm\\(cm\\)byClass[“Specificity”], res_knn\\(cm\\)byClass[“Specificity”], res_svm\\(cm\\)byClass[“Specificity”]),\nAUC = c(res_glm\\(auc, res_rpart\\)auc, res_rf\\(auc,\n          res_gbm\\)auc, res_knn\\(auc, res_svm\\)auc) )\nmodel_comparison %&gt;% mutate(across(2:5, round, 4))\nSummary of Table\nAccuracy is misleading high (~95% for all models)\nSensitivity is nearly zero for most models\nGBM, RF, and Logistic show best AUC\nDecision Tree performs moderately\nkNN and SVM perform poorly\n\nThreshold Adjustment (Improving Sensitivity)\n\nBecause stroke is rare, using the default probability threshold of 0.5 causes models to miss all positive cases.\nWe tested a lower threshold of 0.3 for GBM:\nprobs &lt;- predict(fit_gbm, newdata = test_data, type = “prob”)[,“Yes”] preds &lt;- ifelse(probs &gt; 0.3, “Yes”, “No”) confusionMatrix(factor(preds), test_data$stroke, positive=“Yes”)\nOutput Summary\n\nSensitivity improved from 0% → 8.1%\nSpecificity remained high (98.8%)\nAccuracy slightly decreased (95.17% → 94.45%)\nBalanced Accuracy increased (0.50 → 0.53)\nModel correctly identified 6 stroke cases after tuning\n\nInterpretation\nLowering the threshold improves detection of rare events and is a common technique for medical prediction tasks\nFinal Interpretation of Results\n\nGBM and Random Forest showed the strongest overall discriminative performance (AUC).\nLogistic Regression surprisingly performed well given its simplicity.\nAll models struggled with sensitivity due to the high class imbalance.\nThreshold adjustment improved sensitivity and detection of stroke cases.\nAccuracy alone is misleading for this dataset since predicting “No stroke” yields 95% accuracy.\n\nSummary\nThis results section demonstrates that:\n\nGBM is the best-performing model overall\nSensitivity requires threshold tuning or imbalance techniques\nROC and AUC give a much clearer picture than accuracy\nImbalanced medical datasets pose significant modeling challenges"
  },
  {
    "objectID": "sections/models.html",
    "href": "sections/models.html",
    "title": "Models",
    "section": "",
    "text": "This section describes the development of the six supervised machine-learning models used to predict stroke occurrence. All models were trained using the caret package with the same repeated 5-fold cross-validation structure and ROC-based optimization.\n\n\nModel Formula\nAll models used the same predictor formula:\n```r model_formula &lt;- stroke ~ age + gender + hypertension + heart_disease + ever_married + work_type + residence_type + avg_glucose_level + bmi + smoking_status\nCross-Validation Setup\nctrl &lt;- trainControl( method = “repeatedcv”, number = 5, repeats = 3, classProbs = TRUE, summaryFunction = twoClassSummary ) This ensures fair comparison across all models.\n\nLogistic Regression\n\nset.seed(123) fit_glm &lt;- train( model_formula, data = train_data, method = “glm”, family = “binomial”, trControl = ctrl, metric = “ROC” ) fit_glm\nKey Findings\n\nROC ≈ 0.8456\nSensitivity = very low (model predicts almost all “No stroke”)\nSpecificity ≈ 1.00\nAUC ≈ 0.8167\nAge, Hypertension, and Glucose Level were the most important predictors.\n\nvarImp(fit_glm)\nLogistic regression performed well in terms of ROC, but class imbalance caused it to miss most stroke cases.\n\nDecision Tree (rpart)\n\nset.seed(123) fit_rpart &lt;- train( model_formula, data = train_data, method = “rpart”, trControl = ctrl, metric = “ROC” ) fit_rpart\nKey Findings\n\nROC ≈ 0.738\nSensitivity slightly higher than other simple models\nTop predictors: Age, Hypertension, Glucose Level\n\nPlot the tree: rpart.plot(fit_rpart$finalModel)\nDecision trees are interpretable but struggle with imbalanced data.\n\nGradient Boosted Machine (GBM) set.seed(123) fit_gbm &lt;- train( model_formula, data = train_data, method = “gbm”, trControl = ctrl, metric = “ROC”, verbose = FALSE ) fit_gbm\n\nKey Findings\n\nROC ≈ 0.845 (highest among all models)\nAUC ≈ 0.810\nStrong classifier, but low sensitivity due to rare stroke cases\n\nMost important predictors:\n\nAge\nAverage Glucose\nHypertension\n\nvarImp(fit_gbm)\nGBM showed the best discriminative power in your project.\n\nRandom Forest set.seed(123) fit_rf &lt;- train( model_formula, data = train_data, method = “rf”, trControl = ctrl, metric = “ROC” ) fit_rf\n\nKey Findings\n\nROC ≈ 0.821\nAUC ≈ 0.805\nSensitivity still low\n\nVariable importance ranks:\n\nGlucose\nBMI\nAge\n\nvarImp(fit_rf)\n\nk-Nearest Neighbors (kNN)\n\nset.seed(123) fit_knn &lt;- train( model_formula, data = train_data, method = “knn”, trControl = ctrl, metric = “ROC”, preProcess = c(“center”, “scale”) ) fit_knn\nKey Findings\n\nROC increases slightly with larger k\nAUC ≈ 0.678\nPredicted No stroke for all cases (0% sensitivity)\nkNN struggles heavily with imbalanced datasets.\n\n\nSupport Vector Machine (Radial Kernel) set.seed(123) fit_svm &lt;- train( model_formula, data = train_data, method = “svmRadial”, trControl = ctrl, metric = “ROC”, preProcess = c(“center”, “scale”) ) fit_svm\n\nKey Findings\n\nAUC ≈ 0.639\nHigh accuracy but 0% sensitivity\nPredicted all cases as “No stroke”\nSVM performed poorly on this dataset due to the rarity of stroke events.\n\nSummary of All Models\nGBM and Random Forest were the strongest models in terms of AUC and ROC.\nLogistic Regression also performed surprisingly well but still struggled with identifying positive stroke cases.\nSimple classifiers (kNN, SVM, Decision Tree) had weaker performance due to data imbalance.\nROC Curves for All Models plot(res_glm\\(roc_obj, col=\"black\", lwd=2, main=\"ROC Curves (6 Models)\")\nplot(res_rpart\\)roc_obj, col=“orange”, lwd=2, add=TRUE) plot(res_rf\\(roc_obj, col=\"red\", lwd=2, add=TRUE)\nplot(res_gbm\\)roc_obj, col=“blue”, lwd=2, add=TRUE) plot(res_knn\\(roc_obj, col=\"brown\", lwd=2, add=TRUE)\nplot(res_svm\\)roc_obj, col=“darkgreen”, lwd=2, add=TRUE)\nConclusion\n\nGBM had the highest AUC and ROC performance.\nRandom Forest closely followed.\nLogistic Regression performed moderately well.\nDecision Tree, kNN, and SVM performed poorly due to imbalance."
  },
  {
    "objectID": "sections/literature_review.html",
    "href": "sections/literature_review.html",
    "title": "Literature Review",
    "section": "",
    "text": "Predicting stroke risk has been widely studied in both clinical research and data science because early identification of high-risk individuals greatly improves long-term outcomes. Prior literature consistently emphasizes the importance of demographic, behavioral, and clinical features when modeling stroke, including age, hypertension, heart disease, BMI, diabetes, glucose levels, and smoking behavior.\nKaggle’s publicly available stroke dataset has been used by several studies to evaluate machine-learning models for early stroke detection. Kaur and Kumar (2019) reported that logistic regression and random forest models performed reasonably well, with age and glucose level being the most influential predictors. However, they also noted that extreme class imbalance caused many models to default to predicting the majority class (“No stroke”).\nMohanty et al. (2020) compared multiple ensemble methods and found that Gradient Boosting and Random Forest achieved the strongest performance, with AUC values above 0.80. They observed that ensemble models tend to capture complex nonlinear relationships better than simpler linear models, especially in medical datasets.\nAmin et al. (2021) highlighted the importance of handling class imbalance properly. They demonstrated that techniques such as SMOTE oversampling, class-weight adjustments, and probability-threshold tuning can significantly increase the sensitivity of minority-class predictions while maintaining overall model stability. Without these adjustments, most models struggle to identify rare health events like stroke.\nAcross the literature, two themes consistently appear:\n\nTree-based ensemble models outperform most other algorithms in terms of ROC and AUC.\n\nImbalanced datasets create major challenges, often resulting in very low sensitivity unless corrective measures are used.\n\nThese findings strongly support our decision to evaluate multiple modeling techniques and to carefully examine performance metrics beyond accuracy, such as sensitivity, specificity, and AUC."
  },
  {
    "objectID": "sections/data_cleaning.html",
    "href": "sections/data_cleaning.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "This section describes the detailed data-cleaning steps performed to prepare the stroke dataset for machine-learning modeling. Proper data cleaning ensures accuracy, prevents data leakage, and improves model stability — especially for rare outcomes such as stroke."
  },
  {
    "objectID": "sections/data_cleaning.html#removing-non-predictive-identifiers",
    "href": "sections/data_cleaning.html#removing-non-predictive-identifiers",
    "title": "Data Cleaning",
    "section": "1. Removing Non-Predictive Identifiers",
    "text": "1. Removing Non-Predictive Identifiers\nThe dataset included an ID column that does not contribute to prediction.\nIt was removed to prevent noise in the model:\n```r stroke &lt;- stroke %&gt;% select(-id)\n##2. Converting Variables to Appropriate Data Types\nThe dataset contains multiple categorical variables that must be treated as factors in R to ensure correct modeling. stroke &lt;- stroke %&gt;% mutate( gender = factor(gender), ever_married = factor(ever_married), work_type = factor(work_type), residence_type = factor(residence_type), smoking_status = factor(smoking_status), hypertension = factor(hypertension), heart_disease = factor(heart_disease), stroke = factor(stroke, levels = c(0, 1), labels = c(“No”, “Yes”)) )\n\n3. Handling Rare Categories\nThe gender variable contained one instance labeled “Other”:\ntable(stroke$gender)\nOutput initially: Female Male Other 2994 2115 1\nTo avoid model instability, the “Other” case was merged into the “Male” category:\nstroke\\(gender[stroke\\)gender == “Other”] &lt;- “Male” stroke\\(gender &lt;- droplevels(stroke\\)gender)\nUpdated: Female Male 2994 2116\n\nCleaning and Imputing BMI Values\n\nThe BMI column contained missing entries and irregular values such as “N/A”.\n4.1 Convert invalid entries to NA stroke\\(bmi[stroke\\)bmi == “N/A”] &lt;- NA stroke\\(bmi &lt;- as.numeric(stroke\\)bmi)\n4.2 Impute missing values using median median_bmi &lt;- median(stroke\\(bmi, na.rm = TRUE)\nstroke\\)bmi[is.na(stroke$bmi)] &lt;- median_bmi\n4.3 Summary of cleaned BMI summary(stroke$bmi)\nExpected output: Min. 1st Qu. Median Mean 3rd Qu. Max. 10.3 23.8 28.1 28.9 32.8 97.6\nInterpretation\n\nBMI ranges from 10.3 to 97.6\nMedian BMI ≈ 28.1 (overweight category)\nMean slightly above median → slight right skew\nIndicates presence of high-BMI outliers\n\n\nFinal Missing-Value Check After cleaning all variables:\n\nsapply(stroke, function(x) sum(is.na(x)))\nExpected result: gender 0 age 0 hypertension 0 heart_disease 0 ever_married 0 work_type 0 residence_type 0 avg_glucose_level 0 bmi 0 smoking_status 0 stroke 0\nNo missing values remain in the dataset.\n\nClass Imbalance Verification\n\nStroke is a rare event (~5%), which must be accounted for in model evaluation.\nprop.table(table(stroke$stroke))\nExpected output: No Yes 0.951 0.049\nConfirms high class imbalance, which affects sensitivity and ROC behavior.\nSummary\nAfter data cleaning:\n\nAll categorical variables were converted to factors\nNon-predictive ID field removed\nGender rare category fixed\nBMI cleaned, converted, and median-imputed\nNo missing data remained\nClass imbalance confirmed (~95% No Stroke / 5% Stroke)\n\nThis cleaned dataset is now ready for reliable model development."
  },
  {
    "objectID": "docs/sections/introduction.html",
    "href": "docs/sections/introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Stroke frequently happens suddenly, but by figuring out what causes it, we may utilize data analysis to forecast risk and find significant trends. These revelations enable people to take knowledgeable actions toward improved health by increasing awareness.The World Health Organization reports that millions of people suffer from hemorrhagic or ischemic stroke every year, and many of these patients have long-term neurological disability. Early detection of high-risk individuals can facilitate prompt intervention, lifestyle changes, and better patient outcomes. Machine-learning algorithms are now useful for predicting stroke risk based on clinical and demographic characteristics due to the growing availability of health data and computational resources. Our project of 3 is maininly focused on utilizing a stroke dataset that includes important patient characteristics, such as age, gender, medical history (heart disease and hypertension), behavioral factors (smoking status, physical living environment), and physiological measurements like body mass index (BMI) and average blood glucose levels, to create a thorough predictive modeling framework. This dataset is appropriate for exploratory and predictive analysis since these variables have been extensively researched in.\nThere are 3 main objectives for our research\n• Data cleaning:\n• Create different modeling techniques – I am using 6 different modeling technique, I am good with to find out the best result. ( Logistic Regression, Decision Tree , Random Forest, Gradient Boosted Machine, k-Nearest Neighbors , Support Vector Machine – radial • Performance result: To choose the most near perfect model for stroke classification, evaluate each model using accuracy, sensitivity, specificity, ROC curves, AUC, and confusion matrices.\nThis study seeks to determine the best-performing classifier as well as the predictors that most significantly influence the chance of stroke by methodically assessing a wide range of models."
  },
  {
    "objectID": "sections/conclusion.html",
    "href": "sections/conclusion.html",
    "title": "Conclusion",
    "section": "",
    "text": "This project applied six supervised machine-learning models to a highly imbalanced medical dataset to predict the likelihood of stroke based on demographic, behavioral, and clinical risk factors. Through a structured process of data cleaning, stratified sampling, and repeated cross-validation, the models were evaluated using robust metrics including AUC, sensitivity, specificity, and ROC curves."
  },
  {
    "objectID": "sections/conclusion.html#key-findings",
    "href": "sections/conclusion.html#key-findings",
    "title": "Conclusion",
    "section": "Key Findings",
    "text": "Key Findings\n\n1. Ensemble models performed best\nGradient Boosted Machine (GBM) and Random Forest consistently showed the strongest discriminative performance:\n\nGBM AUC ≈ 0.810\nRandom Forest AUC ≈ 0.805\nLogistic Regression AUC ≈ 0.817\n\nThese models captured important nonlinear relationships in the data.\n\n\n2. All models struggled with sensitivity\nDue to extreme class imbalance (~5% stroke cases):\n\nFive out of six models predicted 0 true positives\nSensitivity was nearly 0%\nAccuracy was misleadingly high (~95%) because the majority class dominates\n\nThis highlights a major challenge in rare-event medical modeling.\n\n\n3. Threshold adjustment improved detection\nLowering the decision threshold for GBM from 0.5 to 0.3:\n\nSensitivity improved from 0% to 8.1%\nSpecificity remained high (98.8%)\nBalanced accuracy increased\nThe model correctly identified several stroke cases that were previously missed\n\nThis demonstrates the practical value of threshold tuning in imbalanced datasets.\n\n\n4. Important predictors\nAcross models, the most influential predictors were:\n\nAge\nAverage glucose level\nHypertension\n\nBMI\n\nSmoking status (never smoked / unknown)"
  },
  {
    "objectID": "sections/conclusion.html#limitations",
    "href": "sections/conclusion.html#limitations",
    "title": "Conclusion",
    "section": "Limitations",
    "text": "Limitations\n\nThe dataset is highly imbalanced, making sensitivity difficult to achieve.\n\nThere is limited clinical detail (e.g., cholesterol, blood pressure ranges).\n\nMost models default to predicting the majority class without specialized imbalance handling."
  },
  {
    "objectID": "sections/conclusion.html#final-summary",
    "href": "sections/conclusion.html#final-summary",
    "title": "Conclusion",
    "section": "Final Summary",
    "text": "Final Summary\nThis project applied six supervised machine-learning models to a highly imbalanced medical dataset to predict the likelihood of stroke based on demographic, behavioral, and clinical risk factors. Through a structured process of data cleaning, stratified sampling, and repeated cross-validation, the models were evaluated using robust metrics including AUC, sensitivity, specificity, and ROC curves."
  },
  {
    "objectID": "sections/conclusion.html#key-findings-1",
    "href": "sections/conclusion.html#key-findings-1",
    "title": "Conclusion",
    "section": "Key Findings",
    "text": "Key Findings\n\n1. Ensemble models performed best\nGradient Boosted Machine (GBM) and Random Forest consistently showed the strongest discriminative performance:\n\nGBM AUC ≈ 0.810\nRandom Forest AUC ≈ 0.805\nLogistic Regression AUC ≈ 0.817\n\nThese models captured important nonlinear relationships in the data.\n\n\n2. All models struggled with sensitivity\nDue to extreme class imbalance (~5% stroke cases):\n\nFive out of six models predicted 0 true positives\nSensitivity was nearly 0%\nAccuracy was misleadingly high (~95%) because the majority class dominates\n\nThis highlights a major challenge in rare-event medical modeling.\n\n\n3. Threshold adjustment improved detection\nLowering the decision threshold for GBM from 0.5 → 0.3:\n\nSensitivity improved from 0% → 8.1%\nSpecificity remained high (98.8%)\nBalanced accuracy increased\nThe model correctly identified several stroke cases that were previously missed\n\nThis demonstrates the practical value of threshold tuning in imbalanced datasets.\n\n\n4. Important predictors\nAcross models, the most influential predictors were:\n\nAge\n\nAverage glucose level\n\nHypertension\n\nBMI\n\nSmoking status (never smoked / unknown)\n\nThese findings match published research in stroke-risk prediction."
  },
  {
    "objectID": "sections/conclusion.html#limitations-1",
    "href": "sections/conclusion.html#limitations-1",
    "title": "Conclusion",
    "section": "Limitations",
    "text": "Limitations\n\nThe dataset is highly imbalanced, making sensitivity difficult to achieve.\n\nThere is limited clinical detail (e.g., cholesterol, blood pressure ranges).\n\nMost models default to predicting the majority class without specialized imbalance handling."
  },
  {
    "objectID": "sections/conclusion.html#final-summary-1",
    "href": "sections/conclusion.html#final-summary-1",
    "title": "Conclusion",
    "section": "Final Summary",
    "text": "Final Summary\nDespite the challenges posed by severe class imbalance, this project successfully implemented and compared six supervised machine-learning models—Logistic Regression, Decision Tree, Random Forest, Gradient Boosting (GBM), k-Nearest Neighbors, and Support Vector Machine—to predict stroke occurrence using demographic, behavioral, and clinical features. The results showed that ensemble-based methods, particularly GBM and Random Forest, consistently delivered the strongest discriminative performance with high AUC values and robust ROC behavior. Logistic Regression also performed competitively, reinforcing its usefulness as a baseline model even in complex health prediction tasks.\nHowever, the findings also highlight the difficulty of identifying stroke cases in datasets where the minority class represents fewer than 5% of all observations. Most models achieved high accuracy by simply predicting the majority class (“No stroke”), leading to extremely low sensitivity. This underscores the limitations of traditional accuracy metrics in healthcare contexts and the need for evaluation methods that prioritize minority-class detection. By adjusting the probability threshold, the GBM model demonstrated a measurable improvement in sensitivity, successfully identifying cases that all models previously misclassified. This confirms that simple post-processing strategies, such as threshold tuning, can significantly improve the clinical utility of machine-learning models.\nOverall, the study demonstrates that meaningful stroke prediction is possible but requires thoughtful handling of class imbalance and careful interpretation of model performance metrics. The project provides a strong foundation for more sophisticated modeling approaches such as class weighting, SMOTE oversampling, cost-sensitive learning, and advanced gradient-boosting algorithms like XGBoost or LightGBM. As the prevalence of stroke continues to rise worldwide, improving early-risk prediction with data-driven tools can contribute to earlier interventions, more targeted patient monitoring, and ultimately better public health outcomes."
  },
  {
    "objectID": "sections/Introduction.html",
    "href": "sections/Introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Stroke frequently happens suddenly, but by figuring out what causes it, we may utilize data analysis to forecast risk and find significant trends. These revelations enable people to take knowledgeable actions toward improved health by increasing awareness.The World Health Organization reports that millions of people suffer from hemorrhagic or ischemic stroke every year, and many of these patients have long-term neurological disability. Early detection of high-risk individuals can facilitate prompt intervention, lifestyle changes, and better patient outcomes. Machine-learning algorithms are now useful for predicting stroke risk based on clinical and demographic characteristics due to the growing availability of health data and computational resources. Our project of 3 is maininly focused on utilizing a stroke dataset that includes important patient characteristics, such as age, gender, medical history (heart disease and hypertension), behavioral factors (smoking status, physical living environment), and physiological measurements like body mass index (BMI) and average blood glucose levels, to create a thorough predictive modeling framework. This dataset is appropriate for exploratory and predictive analysis since these variables have been extensively researched in.\nThere are 3 main objectives for our research\n• Data cleaning:\n• Create different modeling techniques – I am using 6 different modeling technique, I am good with to find out the best result. ( Logistic Regression, Decision Tree , Random Forest, Gradient Boosted Machine, k-Nearest Neighbors , Support Vector Machine – radial • Performance result: To choose the most near perfect model for stroke classification, evaluate each model using accuracy, sensitivity, specificity, ROC curves, AUC, and confusion matrices.\nThis study seeks to determine the best-performing classifier as well as the predictors that most significantly influence the chance of stroke by methodically assessing a wide range of models."
  },
  {
    "objectID": "sections/methodology.html",
    "href": "sections/methodology.html",
    "title": "Methodology",
    "section": "",
    "text": "This project follows a structured machine-learning workflow consisting of four key phases: data understanding, data preparation, model development, and model evaluation. The goal of the methodology is to ensure clean data, prevent data leakage, and allow fair comparison across six classification models."
  },
  {
    "objectID": "sections/methodology.html#dataset-description",
    "href": "sections/methodology.html#dataset-description",
    "title": "Methodology",
    "section": "1. Dataset Description",
    "text": "1. Dataset Description\nThis study uses a publicly available stroke dataset from Kaggle that contains 5,110 observations describing demographic, behavioral, and clinical features associated with stroke risk. Variables include:\n\nAge\n\nGender\n\nHypertension\n\nHeart disease\n\nMarital status\n\nWork type\n\nResidence type\n\nSmoking status\n\nBMI\n\nAverage glucose level\n\nThe outcome variable stroke is binary (Yes/No).\nOnly ~5% of individuals experienced a stroke, making this a highly imbalanced dataset — a challenge addressed throughout the methodology."
  },
  {
    "objectID": "sections/methodology.html#data-cleaning-and-preparation",
    "href": "sections/methodology.html#data-cleaning-and-preparation",
    "title": "Methodology",
    "section": "2. Data Cleaning and Preparation",
    "text": "2. Data Cleaning and Preparation\nData preparation is one of the most important steps because incorrect data types, missing values, and rare categories can create misleading model performance.\n\n2.1 Removing non-predictive identifiers\nThe dataset contained an ID field that had no predictive value:\n```r stroke &lt;- stroke %&gt;% select(-id)\n###2.2 Recoding and converting categorical variables to factors\nCategorical variables were converted to factors for proper model handling:\nstroke &lt;- stroke %&gt;% mutate( gender = factor(gender), ever_married = factor(ever_married), work_type = factor(work_type), residence_type = factor(residence_type), smoking_status = factor(smoking_status), hypertension = factor(hypertension), heart_disease = factor(heart_disease), stroke = factor(stroke, levels = c(0,1), labels = c(“No”,“Yes”)) ) ###2.3 Handling rare categories The gender variable contained one case labeled “Other.” To avoid model instability: ###2.4 Cleaning and imputing BMI The BMI variable contained missing values and entries such as “N/A”. These were converted and imputed using the median:\nstroke\\(bmi[stroke\\)bmi == “N/A”] &lt;- NA stroke\\(bmi &lt;- as.numeric(stroke\\)bmi) median_bmi &lt;- median(stroke\\(bmi, na.rm = TRUE)\nstroke\\)bmi[is.na(stroke$bmi)] &lt;- median_bmi\nBMI ranged from 10.3 to 97.6, with a median of 28.1, indicating a slightly right-skewed distribution due to high-BMI outliers.\n2.5 Verifying data integrity A final missing-value check confirmed the dataset was complete:\nsapply(stroke, function(x) sum(is.na(x)))\n\nTrain/Test Split (Preventing Data Leakage)\n\nTo maintain class proportions while preventing data leakage, a stratified 70/30 split was used:\nset.seed(123) index &lt;- createDataPartition(stroke$stroke, p = 0.7, list = FALSE) train_data &lt;- stroke[index, ] test_data &lt;- stroke[-index, ]\nBoth training and test sets retained the same imbalance ratio (~5% stroke).\n\nCross-Validation\n\nAll models were trained using:\n\n5-fold cross-validation\n3 repetitions\nROC (AUC) as the optimization metric\n\nctrl &lt;- trainControl( method = “repeatedcv”, number = 5, repeats = 3, classProbs = TRUE, summaryFunction = twoClassSummary )\nThis ensures stable model comparison and reduces overfitting.\n\nModel Development (Six Classification Models)\n\nSix supervised learning models were trained using consistent preprocessing and cross-validation settings:\n\nLogistic Regression\nDecision Tree (rpart)\nRandom Forest\nGradient Boosted Machine (GBM)\nk-Nearest Neighbors (kNN)\nSupport Vector Machine (Radial Kernel)\n\nAll models used the same formula and training control:\nfit_model &lt;- train( model_formula, data = train_data, method = “…”, trControl = ctrl, metric = “ROC” )\nThis provides a fair, apples-to-apples comparison.\n\nModel Evaluation\n\nEach model was evaluated on the test set using:\nConfusion matrix\nAccuracy\nSensitivity (Recall)\nSpecificity\nROC curve\nArea Under Curve (AUC)\nA custom evaluation function was used to standardize comparison:\nevaluate_model &lt;- function(model, test_data, positive_class = “Yes”) { pred_class &lt;- predict(model, newdata = test_data) pred_prob &lt;- predict(model, newdata = test_data, type = “prob”)[, positive_class] cm &lt;- confusionMatrix(pred_class, test_data$stroke, positive = positive_class)\nroc_obj &lt;- roc( response = test_data$stroke, predictor = pred_prob, levels = c(“No”, “Yes”) )\nlist( cm = cm, auc = auc(roc_obj), roc_obj = roc_obj ) }\nUsing these metrics provides a complete understanding of each model’s ability to detect rare stroke cases.\nThis combined methodology from both project drafts ensures:\nClean, consistent, and reliable data\nNo data leakage\nProper handling of class imbalance\nFair cross-validated comparison across models\nA complete evaluation of model performance\nThis workflow provides a strong foundation for accurate and interpretable stroke prediction."
  },
  {
    "objectID": "sections/references.html",
    "href": "sections/references.html",
    "title": "References",
    "section": "",
    "text": "Krekorian, N. (2020). Stroke Prediction Dataset. Kaggle.\nhttps://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset"
  },
  {
    "objectID": "sections/references.html#dataset",
    "href": "sections/references.html#dataset",
    "title": "References",
    "section": "",
    "text": "Krekorian, N. (2020). Stroke Prediction Dataset. Kaggle.\nhttps://www.kaggle.com/datasets/fedesoriano/stroke-prediction-dataset"
  },
  {
    "objectID": "sections/references.html#key-research-used-in-literature-review",
    "href": "sections/references.html#key-research-used-in-literature-review",
    "title": "References",
    "section": "Key Research Used in Literature Review",
    "text": "Key Research Used in Literature Review\nAmin, R., Hasan, M., & Islam, M. (2021). Predicting stroke disease using machine learning classifiers with SMOTE for balancing class imbalance. Journal of Computer Science, 17(4), 327–338.\nKaur, H., & Kumar, R. (2019). Predictive modeling for stroke detection using machine learning algorithms. International Journal of Engineering and Advanced Technology, 8(6), 1230–1235.\nMohanty, S., Gupta, D., & Dhara, B. (2020). Stroke prediction using machine learning techniques: A comprehensive study. International Journal of Advanced Computer Science and Applications, 11(5), 440–448.\nWorld Health Organization. (2023). Stroke Fact Sheet. https://www.who.int"
  },
  {
    "objectID": "sections/references.html#r-packages",
    "href": "sections/references.html#r-packages",
    "title": "References",
    "section": "R Packages",
    "text": "R Packages\nKuhn, M. (2022). caret: Classification and Regression Training. R package version 6.0–94.\nhttps://CRAN.R-project.org/package=caret\nRobin, X. et al. (2011). pROC: Display and Analyze ROC Curves.\nhttps://CRAN.R-project.org/package=pROC\nR Core Team. (2024). R: A Language and Environment for Statistical Computing.\nhttps://www.r-project.org/\nGreenwell, B., Boehmke, B., & Gray, B. (2020). gbm: Generalized Boosting Models.\nhttps://CRAN.R-project.org/package=gbm\nLiaw, A., & Wiener, M. (2002). RandomForest: Breiman and Cutler’s Random Forests for Classification and Regression.\nhttps://CRAN.R-project.org/package=randomForest\nVenables, W., & Ripley, B. (2002). Modern Applied Statistics with S. Springer."
  },
  {
    "objectID": "sections/references.html#additional-references",
    "href": "sections/references.html#additional-references",
    "title": "References",
    "section": "Additional References",
    "text": "Additional References\nJames, G., Witten, D., Hastie, T., & Tibshirani, R. (2021). An Introduction to Statistical Learning (2nd ed.). Springer.\nKuhn, M., & Johnson, K. (2013). Applied Predictive Modeling. Springer."
  },
  {
    "objectID": "sections/references.html#notes",
    "href": "sections/references.html#notes",
    "title": "References",
    "section": "Notes",
    "text": "Notes\nThis reference list includes:\n\nAll sources used in the introduction and literature review\n\nCredited datasets\n\nBooks and academic resources relevant to machine-learning modeling\n\nKey R packages used in the analysis"
  }
]