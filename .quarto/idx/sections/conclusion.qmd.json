{"title":"Conclusion","markdown":{"yaml":{"title":"Conclusion"},"headingText":"Key Findings","containsRefs":false,"markdown":"\n\nThis project applied six supervised machine-learning models to a highly imbalanced medical dataset to predict the likelihood of stroke based on demographic, behavioral, and clinical risk factors. Through a structured process of data cleaning, stratified sampling, and repeated cross-validation, the models were evaluated using robust metrics including AUC, sensitivity, specificity, and ROC curves.\n\n---\n\n\n### 1. Ensemble models performed best\nGradient Boosted Machine (GBM) and Random Forest consistently showed the strongest discriminative performance:\n\n- GBM AUC ≈ 0.810\n- Random Forest AUC ≈ 0.805\n- Logistic Regression AUC ≈ 0.817\n\nThese models captured important nonlinear relationships in the data.\n\n### 2. All models struggled with sensitivity\nDue to extreme class imbalance (~5% stroke cases):\n\n- Five out of six models predicted 0 true positives\n- Sensitivity was nearly 0%\n- Accuracy was misleadingly high (~95%) because the majority class dominates\n\nThis highlights a major challenge in rare-event medical modeling.\n\n### 3. Threshold adjustment improved detection\nLowering the decision threshold for GBM from 0.5 to 0.3:\n\n- Sensitivity improved from 0% to 8.1%\n- Specificity remained high (98.8%)\n- Balanced accuracy increased\n- The model correctly identified several stroke cases that were previously missed\n\nThis demonstrates the practical value of threshold tuning in imbalanced datasets.\n\n### 4. Important predictors\nAcross models, the most influential predictors were:\n\n- Age \n- Average glucose level\n- Hypertension  \n- BMI  \n- Smoking status (never smoked / unknown) \n\n\n---\n\n## Limitations\n\n- The dataset is highly imbalanced, making sensitivity difficult to achieve.  \n- There is limited clinical detail (e.g., cholesterol, blood pressure ranges).  \n- Most models default to predicting the majority class without specialized imbalance handling.  \n\n---\n\n\n## Final Summary\n\n---\ntitle: \"Conclusion\"\n---\n\nThis project applied six supervised machine-learning models to a highly imbalanced medical dataset to predict the likelihood of stroke based on demographic, behavioral, and clinical risk factors. Through a structured process of data cleaning, stratified sampling, and repeated cross-validation, the models were evaluated using robust metrics including AUC, sensitivity, specificity, and ROC curves.\n\n---\n\n## Key Findings\n\n### **1. Ensemble models performed best**\nGradient Boosted Machine (GBM) and Random Forest consistently showed the strongest discriminative performance:\n\n- GBM AUC ≈ **0.810**\n- Random Forest AUC ≈ **0.805**\n- Logistic Regression AUC ≈ **0.817**\n\nThese models captured important nonlinear relationships in the data.\n\n### **2. All models struggled with sensitivity**\nDue to extreme class imbalance (~5% stroke cases):\n\n- Five out of six models predicted **0 true positives**\n- Sensitivity was nearly **0%**\n- Accuracy was misleadingly high (~95%) because the majority class dominates\n\nThis highlights a major challenge in rare-event medical modeling.\n\n### **3. Threshold adjustment improved detection**\nLowering the decision threshold for GBM from **0.5 → 0.3**:\n\n- Sensitivity improved from **0% → 8.1%**\n- Specificity remained high (**98.8%**)\n- Balanced accuracy increased\n- The model correctly identified several stroke cases that were previously missed\n\nThis demonstrates the practical value of threshold tuning in imbalanced datasets.\n\n### **4. Important predictors**\nAcross models, the most influential predictors were:\n\n- **Age**  \n- **Average glucose level**  \n- **Hypertension**  \n- **BMI**  \n- **Smoking status (never smoked / unknown)**  \n\nThese findings match published research in stroke-risk prediction.\n\n---\n\n## Limitations\n\n- The dataset is **highly imbalanced**, making sensitivity difficult to achieve.  \n- There is limited clinical detail (e.g., cholesterol, blood pressure ranges).  \n- Most models default to predicting the majority class without specialized imbalance handling.  \n\n\n## Final Summary\n\nDespite the challenges posed by severe class imbalance, this project successfully implemented and compared six supervised machine-learning models—Logistic Regression, Decision Tree, Random Forest, Gradient Boosting (GBM), k-Nearest Neighbors, and Support Vector Machine—to predict stroke occurrence using demographic, behavioral, and clinical features. The results showed that ensemble-based methods, particularly GBM and Random Forest, consistently delivered the strongest discriminative performance with high AUC values and robust ROC behavior. Logistic Regression also performed competitively, reinforcing its usefulness as a baseline model even in complex health prediction tasks.\n\nHowever, the findings also highlight the difficulty of identifying stroke cases in datasets where the minority class represents fewer than 5% of all observations. Most models achieved high accuracy by simply predicting the majority class (“No stroke”), leading to extremely low sensitivity. This underscores the limitations of traditional accuracy metrics in healthcare contexts and the need for evaluation methods that prioritize minority-class detection. By adjusting the probability threshold, the GBM model demonstrated a measurable improvement in sensitivity, successfully identifying cases that all models previously misclassified. This confirms that simple post-processing strategies, such as threshold tuning, can significantly improve the clinical utility of machine-learning models.\n\nOverall, the study demonstrates that meaningful stroke prediction is possible but requires thoughtful handling of class imbalance and careful interpretation of model performance metrics. The project provides a strong foundation for more sophisticated modeling approaches such as class weighting, SMOTE oversampling, cost-sensitive learning, and advanced gradient-boosting algorithms like XGBoost or LightGBM. As the prevalence of stroke continues to rise worldwide, improving early-risk prediction with data-driven tools can contribute to earlier interventions, more targeted patient monitoring, and ultimately better public health outcomes.\n","srcMarkdownNoYaml":"\n\nThis project applied six supervised machine-learning models to a highly imbalanced medical dataset to predict the likelihood of stroke based on demographic, behavioral, and clinical risk factors. Through a structured process of data cleaning, stratified sampling, and repeated cross-validation, the models were evaluated using robust metrics including AUC, sensitivity, specificity, and ROC curves.\n\n---\n\n## Key Findings\n\n### 1. Ensemble models performed best\nGradient Boosted Machine (GBM) and Random Forest consistently showed the strongest discriminative performance:\n\n- GBM AUC ≈ 0.810\n- Random Forest AUC ≈ 0.805\n- Logistic Regression AUC ≈ 0.817\n\nThese models captured important nonlinear relationships in the data.\n\n### 2. All models struggled with sensitivity\nDue to extreme class imbalance (~5% stroke cases):\n\n- Five out of six models predicted 0 true positives\n- Sensitivity was nearly 0%\n- Accuracy was misleadingly high (~95%) because the majority class dominates\n\nThis highlights a major challenge in rare-event medical modeling.\n\n### 3. Threshold adjustment improved detection\nLowering the decision threshold for GBM from 0.5 to 0.3:\n\n- Sensitivity improved from 0% to 8.1%\n- Specificity remained high (98.8%)\n- Balanced accuracy increased\n- The model correctly identified several stroke cases that were previously missed\n\nThis demonstrates the practical value of threshold tuning in imbalanced datasets.\n\n### 4. Important predictors\nAcross models, the most influential predictors were:\n\n- Age \n- Average glucose level\n- Hypertension  \n- BMI  \n- Smoking status (never smoked / unknown) \n\n\n---\n\n## Limitations\n\n- The dataset is highly imbalanced, making sensitivity difficult to achieve.  \n- There is limited clinical detail (e.g., cholesterol, blood pressure ranges).  \n- Most models default to predicting the majority class without specialized imbalance handling.  \n\n---\n\n\n## Final Summary\n\n---\ntitle: \"Conclusion\"\n---\n\nThis project applied six supervised machine-learning models to a highly imbalanced medical dataset to predict the likelihood of stroke based on demographic, behavioral, and clinical risk factors. Through a structured process of data cleaning, stratified sampling, and repeated cross-validation, the models were evaluated using robust metrics including AUC, sensitivity, specificity, and ROC curves.\n\n---\n\n## Key Findings\n\n### **1. Ensemble models performed best**\nGradient Boosted Machine (GBM) and Random Forest consistently showed the strongest discriminative performance:\n\n- GBM AUC ≈ **0.810**\n- Random Forest AUC ≈ **0.805**\n- Logistic Regression AUC ≈ **0.817**\n\nThese models captured important nonlinear relationships in the data.\n\n### **2. All models struggled with sensitivity**\nDue to extreme class imbalance (~5% stroke cases):\n\n- Five out of six models predicted **0 true positives**\n- Sensitivity was nearly **0%**\n- Accuracy was misleadingly high (~95%) because the majority class dominates\n\nThis highlights a major challenge in rare-event medical modeling.\n\n### **3. Threshold adjustment improved detection**\nLowering the decision threshold for GBM from **0.5 → 0.3**:\n\n- Sensitivity improved from **0% → 8.1%**\n- Specificity remained high (**98.8%**)\n- Balanced accuracy increased\n- The model correctly identified several stroke cases that were previously missed\n\nThis demonstrates the practical value of threshold tuning in imbalanced datasets.\n\n### **4. Important predictors**\nAcross models, the most influential predictors were:\n\n- **Age**  \n- **Average glucose level**  \n- **Hypertension**  \n- **BMI**  \n- **Smoking status (never smoked / unknown)**  \n\nThese findings match published research in stroke-risk prediction.\n\n---\n\n## Limitations\n\n- The dataset is **highly imbalanced**, making sensitivity difficult to achieve.  \n- There is limited clinical detail (e.g., cholesterol, blood pressure ranges).  \n- Most models default to predicting the majority class without specialized imbalance handling.  \n\n\n## Final Summary\n\nDespite the challenges posed by severe class imbalance, this project successfully implemented and compared six supervised machine-learning models—Logistic Regression, Decision Tree, Random Forest, Gradient Boosting (GBM), k-Nearest Neighbors, and Support Vector Machine—to predict stroke occurrence using demographic, behavioral, and clinical features. The results showed that ensemble-based methods, particularly GBM and Random Forest, consistently delivered the strongest discriminative performance with high AUC values and robust ROC behavior. Logistic Regression also performed competitively, reinforcing its usefulness as a baseline model even in complex health prediction tasks.\n\nHowever, the findings also highlight the difficulty of identifying stroke cases in datasets where the minority class represents fewer than 5% of all observations. Most models achieved high accuracy by simply predicting the majority class (“No stroke”), leading to extremely low sensitivity. This underscores the limitations of traditional accuracy metrics in healthcare contexts and the need for evaluation methods that prioritize minority-class detection. By adjusting the probability threshold, the GBM model demonstrated a measurable improvement in sensitivity, successfully identifying cases that all models previously misclassified. This confirms that simple post-processing strategies, such as threshold tuning, can significantly improve the clinical utility of machine-learning models.\n\nOverall, the study demonstrates that meaningful stroke prediction is possible but requires thoughtful handling of class imbalance and careful interpretation of model performance metrics. The project provides a strong foundation for more sophisticated modeling approaches such as class weighting, SMOTE oversampling, cost-sensitive learning, and advanced gradient-boosting algorithms like XGBoost or LightGBM. As the prevalence of stroke continues to rise worldwide, improving early-risk prediction with data-driven tools can contribute to earlier interventions, more targeted patient monitoring, and ultimately better public health outcomes.\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"conclusion.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","theme":"cosmo","toc-location":"left","title":"Conclusion"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}