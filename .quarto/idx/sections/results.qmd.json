{"title":"Results","markdown":{"yaml":{"title":"Results"},"headingText":"Evaluation Function","containsRefs":false,"markdown":"\n\nThis section presents the performance of all six machine-learning models evaluated on the test dataset. Because the dataset is highly imbalanced (~5% stroke cases), accuracy alone is misleading, so emphasis is placed on **sensitivity**, **specificity**, and **AUC**.\n\n---\n\n\nAll models were evaluated using the same function:\n\n```r\nevaluate_model <- function(model, test_data, positive_class = \"Yes\") {\n  pred_class <- predict(model, newdata = test_data)\n  pred_prob  <- predict(model, newdata = test_data, type = \"prob\")[, positive_class]\n  \n  cm <- confusionMatrix(pred_class, test_data$stroke, positive = positive_class)\n  \n  roc_obj <- roc(\n    response = test_data$stroke,\n    predictor = pred_prob,\n    levels = c(\"No\", \"Yes\")\n  )\n  \n  list(\n    cm = cm,\n    auc = auc(roc_obj),\n    roc_obj = roc_obj\n  )\n}\n\n1. Model Results\n\nEach model was evaluated with the function above:\nres_glm   <- evaluate_model(fit_glm, test_data)\nres_rpart <- evaluate_model(fit_rpart, test_data)\nres_rf    <- evaluate_model(fit_rf, test_data)\nres_gbm   <- evaluate_model(fit_gbm, test_data)\nres_knn   <- evaluate_model(fit_knn, test_data)\nres_svm   <- evaluate_model(fit_svm, test_data)\n\n2. AUC Values\n\n| Model                   | AUC    |\n| ----------------------- | ------ |\n| Logistic Regression     | 0.8167 |\n| Decision Tree           | 0.6950 |\n| Random Forest           | 0.8050 |\n| Gradient Boosting (GBM) | 0.8100 |\n| k-Nearest Neighbors     | 0.6784 |\n| SVM (Radial)            | 0.6390 |\n\nHighest AUC: Logistic Regression (0.8167), GBM (0.810), and Random Forest (0.805).\n\n3. Confusion Matrices (Test Set)\nMost models predicted every case as “No Stroke”, resulting in 0% sensitivity:\n\nLogistic Regression\nres_glm$cm\n\nDecision Tree\nres_rpart$cm\n\nRandom Forest\nres_rf$cm\n\nGBM\nres_gbm$cm\n\nkNN\nres_knn$cm\n\nSVM\nres_svm$cm\n\nAcross models:\n\n- TN (True Negatives) were high\n\n- FP (False Positives) were very low\n\n- TP = 0 almost always\n\n- Sensitivity = 0 for 5 out of 6 models\n\nThis is a typical outcome in highly imbalanced medical datasets.\n\n4. ROC Curve Comparison\nplot(res_glm$roc_obj, col=\"black\", lwd=2, main=\"ROC Curves for Stroke Prediction (6 Models)\")\nplot(res_rpart$roc_obj, col=\"orange\", lwd=2, add=TRUE)\nplot(res_rf$roc_obj,    col=\"red\",    lwd=2, add=TRUE)\nplot(res_gbm$roc_obj,   col=\"blue\",   lwd=2, add=TRUE)\nplot(res_knn$roc_obj,   col=\"brown\",  lwd=2, add=TRUE)\nplot(res_svm$roc_obj,   col=\"darkgreen\", lwd=2, add=TRUE)\n\nROC Interpretation\n\n- GBM (blue) and Random Forest (red) show the best separation.\n\n- Logistic Regression (black) also performs well.\n\n- kNN, SVM, and the Decision Tree show weaker performance.\n\nThis matches the AUC results.\n\n5. Model Comparison Table\nmodel_comparison <- tibble::tibble(\n  Model = c(\"Logistic Regression\", \"Decision Tree\", \"Random Forest\",\n            \"Gradient Boosting (GBM)\", \"k-Nearest Neighbors\", \"SVM (Radial)\"),\n  \n  Accuracy = c(res_glm$cm$overall[\"Accuracy\"],\n               res_rpart$cm$overall[\"Accuracy\"],\n               res_rf$cm$overall[\"Accuracy\"],\n               res_gbm$cm$overall[\"Accuracy\"],\n               res_knn$cm$overall[\"Accuracy\"],\n               res_svm$cm$overall[\"Accuracy\"]),\n  \n  Sensitivity = c(res_glm$cm$byClass[\"Sensitivity\"],\n                  res_rpart$cm$byClass[\"Sensitivity\"],\n                  res_rf$cm$byClass[\"Sensitivity\"],\n                  res_gbm$cm$byClass[\"Sensitivity\"],\n                  res_knn$cm$byClass[\"Sensitivity\"],\n                  res_svm$cm$byClass[\"Sensitivity\"]),\n  \n  Specificity = c(res_glm$cm$byClass[\"Specificity\"],\n                  res_rpart$cm$byClass[\"Specificity\"],\n                  res_rf$cm$byClass[\"Specificity\"],\n                  res_gbm$cm$byClass[\"Specificity\"],\n                  res_knn$cm$byClass[\"Specificity\"],\n                  res_svm$cm$byClass[\"Specificity\"]),\n  \n  AUC = c(res_glm$auc, res_rpart$auc, res_rf$auc,\n          res_gbm$auc, res_knn$auc, res_svm$auc)\n)\n\nmodel_comparison %>% \n  mutate(across(2:5, round, 4))\n\nSummary of Table\n\nAccuracy is misleading high (~95% for all models)\n\nSensitivity is nearly zero for most models\n\nGBM, RF, and Logistic show best AUC\n\nDecision Tree performs moderately\n\nkNN and SVM perform poorly\n\n6. Threshold Adjustment (Improving Sensitivity)\n\nBecause stroke is rare, using the default probability threshold of 0.5 causes models to miss all positive cases.\n\nWe tested a lower threshold of 0.3 for GBM:\n\nprobs <- predict(fit_gbm, newdata = test_data, type = \"prob\")[,\"Yes\"]\npreds <- ifelse(probs > 0.3, \"Yes\", \"No\")\nconfusionMatrix(factor(preds), test_data$stroke, positive=\"Yes\")\n\nOutput Summary\n\n- Sensitivity improved from 0% → 8.1%\n\n- Specificity remained high (98.8%)\n\n- Accuracy slightly decreased (95.17% → 94.45%)\n\n- Balanced Accuracy increased (0.50 → 0.53)\n\n- Model correctly identified 6 stroke cases after tuning\n\nInterpretation\n\nLowering the threshold improves detection of rare events and is a common technique for medical prediction tasks\n\nFinal Interpretation of Results\n\n- GBM and Random Forest showed the strongest overall discriminative performance (AUC).\n\n- Logistic Regression surprisingly performed well given its simplicity.\n\n- All models struggled with sensitivity due to the high class imbalance.\n\n- Threshold adjustment improved sensitivity and detection of stroke cases.\n\n- Accuracy alone is misleading for this dataset since predicting “No stroke” yields 95% accuracy.\n\nSummary\n\nThis results section demonstrates that:\n\n- GBM is the best-performing model overall\n\n- Sensitivity requires threshold tuning or imbalance techniques\n\n- ROC and AUC give a much clearer picture than accuracy\n\n- Imbalanced medical datasets pose significant modeling challenges\n\n","srcMarkdownNoYaml":"\n\nThis section presents the performance of all six machine-learning models evaluated on the test dataset. Because the dataset is highly imbalanced (~5% stroke cases), accuracy alone is misleading, so emphasis is placed on **sensitivity**, **specificity**, and **AUC**.\n\n---\n\n# Evaluation Function\n\nAll models were evaluated using the same function:\n\n```r\nevaluate_model <- function(model, test_data, positive_class = \"Yes\") {\n  pred_class <- predict(model, newdata = test_data)\n  pred_prob  <- predict(model, newdata = test_data, type = \"prob\")[, positive_class]\n  \n  cm <- confusionMatrix(pred_class, test_data$stroke, positive = positive_class)\n  \n  roc_obj <- roc(\n    response = test_data$stroke,\n    predictor = pred_prob,\n    levels = c(\"No\", \"Yes\")\n  )\n  \n  list(\n    cm = cm,\n    auc = auc(roc_obj),\n    roc_obj = roc_obj\n  )\n}\n\n1. Model Results\n\nEach model was evaluated with the function above:\nres_glm   <- evaluate_model(fit_glm, test_data)\nres_rpart <- evaluate_model(fit_rpart, test_data)\nres_rf    <- evaluate_model(fit_rf, test_data)\nres_gbm   <- evaluate_model(fit_gbm, test_data)\nres_knn   <- evaluate_model(fit_knn, test_data)\nres_svm   <- evaluate_model(fit_svm, test_data)\n\n2. AUC Values\n\n| Model                   | AUC    |\n| ----------------------- | ------ |\n| Logistic Regression     | 0.8167 |\n| Decision Tree           | 0.6950 |\n| Random Forest           | 0.8050 |\n| Gradient Boosting (GBM) | 0.8100 |\n| k-Nearest Neighbors     | 0.6784 |\n| SVM (Radial)            | 0.6390 |\n\nHighest AUC: Logistic Regression (0.8167), GBM (0.810), and Random Forest (0.805).\n\n3. Confusion Matrices (Test Set)\nMost models predicted every case as “No Stroke”, resulting in 0% sensitivity:\n\nLogistic Regression\nres_glm$cm\n\nDecision Tree\nres_rpart$cm\n\nRandom Forest\nres_rf$cm\n\nGBM\nres_gbm$cm\n\nkNN\nres_knn$cm\n\nSVM\nres_svm$cm\n\nAcross models:\n\n- TN (True Negatives) were high\n\n- FP (False Positives) were very low\n\n- TP = 0 almost always\n\n- Sensitivity = 0 for 5 out of 6 models\n\nThis is a typical outcome in highly imbalanced medical datasets.\n\n4. ROC Curve Comparison\nplot(res_glm$roc_obj, col=\"black\", lwd=2, main=\"ROC Curves for Stroke Prediction (6 Models)\")\nplot(res_rpart$roc_obj, col=\"orange\", lwd=2, add=TRUE)\nplot(res_rf$roc_obj,    col=\"red\",    lwd=2, add=TRUE)\nplot(res_gbm$roc_obj,   col=\"blue\",   lwd=2, add=TRUE)\nplot(res_knn$roc_obj,   col=\"brown\",  lwd=2, add=TRUE)\nplot(res_svm$roc_obj,   col=\"darkgreen\", lwd=2, add=TRUE)\n\nROC Interpretation\n\n- GBM (blue) and Random Forest (red) show the best separation.\n\n- Logistic Regression (black) also performs well.\n\n- kNN, SVM, and the Decision Tree show weaker performance.\n\nThis matches the AUC results.\n\n5. Model Comparison Table\nmodel_comparison <- tibble::tibble(\n  Model = c(\"Logistic Regression\", \"Decision Tree\", \"Random Forest\",\n            \"Gradient Boosting (GBM)\", \"k-Nearest Neighbors\", \"SVM (Radial)\"),\n  \n  Accuracy = c(res_glm$cm$overall[\"Accuracy\"],\n               res_rpart$cm$overall[\"Accuracy\"],\n               res_rf$cm$overall[\"Accuracy\"],\n               res_gbm$cm$overall[\"Accuracy\"],\n               res_knn$cm$overall[\"Accuracy\"],\n               res_svm$cm$overall[\"Accuracy\"]),\n  \n  Sensitivity = c(res_glm$cm$byClass[\"Sensitivity\"],\n                  res_rpart$cm$byClass[\"Sensitivity\"],\n                  res_rf$cm$byClass[\"Sensitivity\"],\n                  res_gbm$cm$byClass[\"Sensitivity\"],\n                  res_knn$cm$byClass[\"Sensitivity\"],\n                  res_svm$cm$byClass[\"Sensitivity\"]),\n  \n  Specificity = c(res_glm$cm$byClass[\"Specificity\"],\n                  res_rpart$cm$byClass[\"Specificity\"],\n                  res_rf$cm$byClass[\"Specificity\"],\n                  res_gbm$cm$byClass[\"Specificity\"],\n                  res_knn$cm$byClass[\"Specificity\"],\n                  res_svm$cm$byClass[\"Specificity\"]),\n  \n  AUC = c(res_glm$auc, res_rpart$auc, res_rf$auc,\n          res_gbm$auc, res_knn$auc, res_svm$auc)\n)\n\nmodel_comparison %>% \n  mutate(across(2:5, round, 4))\n\nSummary of Table\n\nAccuracy is misleading high (~95% for all models)\n\nSensitivity is nearly zero for most models\n\nGBM, RF, and Logistic show best AUC\n\nDecision Tree performs moderately\n\nkNN and SVM perform poorly\n\n6. Threshold Adjustment (Improving Sensitivity)\n\nBecause stroke is rare, using the default probability threshold of 0.5 causes models to miss all positive cases.\n\nWe tested a lower threshold of 0.3 for GBM:\n\nprobs <- predict(fit_gbm, newdata = test_data, type = \"prob\")[,\"Yes\"]\npreds <- ifelse(probs > 0.3, \"Yes\", \"No\")\nconfusionMatrix(factor(preds), test_data$stroke, positive=\"Yes\")\n\nOutput Summary\n\n- Sensitivity improved from 0% → 8.1%\n\n- Specificity remained high (98.8%)\n\n- Accuracy slightly decreased (95.17% → 94.45%)\n\n- Balanced Accuracy increased (0.50 → 0.53)\n\n- Model correctly identified 6 stroke cases after tuning\n\nInterpretation\n\nLowering the threshold improves detection of rare events and is a common technique for medical prediction tasks\n\nFinal Interpretation of Results\n\n- GBM and Random Forest showed the strongest overall discriminative performance (AUC).\n\n- Logistic Regression surprisingly performed well given its simplicity.\n\n- All models struggled with sensitivity due to the high class imbalance.\n\n- Threshold adjustment improved sensitivity and detection of stroke cases.\n\n- Accuracy alone is misleading for this dataset since predicting “No stroke” yields 95% accuracy.\n\nSummary\n\nThis results section demonstrates that:\n\n- GBM is the best-performing model overall\n\n- Sensitivity requires threshold tuning or imbalance techniques\n\n- ROC and AUC give a much clearer picture than accuracy\n\n- Imbalanced medical datasets pose significant modeling challenges\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"results.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","theme":"cosmo","toc-location":"left","title":"Results"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}